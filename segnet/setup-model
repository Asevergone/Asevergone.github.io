#!/usr/bin/env node
var fs = require('fs')
var path = require('path')

// Set up the caffe model prototxt files for a given training data set
module.exports = setupModel
function setupModel (model, batchSize, trainingData, testData, crop, stats, output) {
  var cw = classWeights(stats).map(function (weight) {
    return 'class_weighting: ' + weight
  })

  batchSize = isNaN(batchSize) ? (model === 'segnet' ? 6 : 16) : batchSize

  renderModel('train', model, cw, output)
  renderModel('inference', model, cw, output)
  renderModel('deploy', model, cw, output)

  // phase: 'train' or 'inference'
  // model: 'segnet' or 'segnet_basic'
  function renderModel (phase, model, classWeights, outputDir) {
    var template = model + '_' + (phase === 'train' ? 'train' : 'inference') + '.prototxt'
    template = path.join(__dirname, 'templates', template)
    var batch = phase === 'train' ? batchSize : 1
    var inputLayer = phase === 'deploy' ? `input: "data"
input_shape: {
  dim: 1
  dim: 3
  dim: 256
  dim: 256
}` : `layer {
  name: "data"
  type: "DenseImageData"
  top: "data"
  top: "label"
  dense_image_data_param {
    source: "${phase === 'train' ? trainingData : testData}"
    batch_size: ${batch}
    shuffle: ${phase === 'train' ? 'true' : 'false'}
    ${crop ? 'crop_height: ' + crop : ''}
    ${crop ? 'crop_width: ' + crop : ''}
  }
}`

    var tmpl = fs.readFileSync(template, 'utf-8')
      .replace(/INPUT/g, inputLayer)
      .replace(/CLASS_COUNT/g, classWeights.length)
      .replace(/(\s+)CLASS_WEIGHTING/g, (_, space) => {
        return classWeights.map(w => space + w).join('')
      })

    var file = path.join(outputDir, model + '_' + phase + '.prototxt')
    fs.writeFileSync(file, tmpl)
  }

  // compute class weighting according to SegNet paper: http://arxiv.org/abs/1511.00561
  function classWeights (stats) {
    var data = fs.readFileSync(stats, 'utf-8').split('\n')
      .slice(1)
      .filter(Boolean)
      .map(x => x.split(',').map(Number))
    var frequencies = data.map(x => x[1] / (x[2] * 65536))
    var sorted = [].concat(frequencies).sort((a, b) => (a - b))
    var n = sorted.length
    var median = n % 2 === 0 ? (sorted[n / 2] + sorted[n / 2 - 1]) / 2 : sorted[n / 2 - 0.5]
    return frequencies.map(x => (median / x))
  }
}

if (require.main === module) {
  var args = require('minimist')(process.argv.slice(2), {
    alias: {
      d: 'data',
      o: 'output',
      m: 'model',
      b: 'batch-size'
    }
  })
  var trainingData = args['train'] || (args['data'] + '/' + 'train.txt')
  var testData = args['test'] || (args['data'] + '/' + 'val.txt')
  var stats = args['label-stats'] || (args['data'] + '/labels/label-stats.csv')
  var model = args['model']
  var output = args['output']
  var crop = args['crop']
  if (!(output && model && stats && trainingData && testData)) {
    console.log('Usage: setup-model --model segnet|segnet_basic --train /path/to/train.txt --test /path/to/train.txt --label-stats /path/to/labelstats.csv --output /path/to/output/dir')
    console.log('label-stats refers to a the label stats csv generated by skynet-data scripts')
    process.exit(1)
  }
  setupModel(model, args.b, trainingData, testData, crop, stats, output)
}
